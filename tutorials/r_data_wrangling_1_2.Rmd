---
title: "R Data Wrangling 1 & 2: Fast-track"
author:
   - name: Andrew Moles
     affiliation: Learning Developer, Digital Skills Lab
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: 
  html_document: 
    theme: readable
    highlight: pygments
    keep_md: no
    code_download: true
    toc: true
    toc_float: 
      collapsed: true
---

# R Data Wrangling 1 - Objective of workshop

To start using the dplyr package from the tidyverse to select columns and filter data. 

# What this workshop will cover

In this workshop, the aim is to cover how to start working with the key library from the tidyverse, dplyr. We will be covering:

-   Introduce the use of pipes
-   Indexing with the select function from dplyr
-   Conditional indexing of data with the filter function from dplyr

------------------------------------------------------------------------

# What is the tidyverse?

![image credit: Analytics Vidhya](https://github.com/andrewmoles2/rTrainIntroduction/blob/main/r-data-wrangling-1/images/tidyverse.jpeg?raw=true)

The tidyverse is a collection of R packages that are designed for data science. These packages share design, syntax, and philosophy. These packages cover the import of data (`readr` and `haven`), manipulation and transformation of data (`dplyr`, `tidyr`, `stringr`, `purrr`, `forcats`, and `lubridate`), visualisation (`ggplot` and it's extensions), and analysis (`tidymodels`).

Essentially, the tidyverse makes data science in R less painless, improving your experience of R and data science, especially in the data cleaning and wrangling stages.

# What is tidy data?

The tidyverse has a focus on working with tidy data, or making data tidy, ready for visualisation and analysis. So what does tidy data mean?

When your data is tidy, *each column is a variable*, *each row is an observation*, and *each cell is a single observation*, as per our example below:

```{r}
# tidy data example
tidy_df <- data.frame(
  id = 1:6,
  name = c("floof", "max", "cat", "donut", "merlin", "panda"),
  colour = c("grey", "black", "orange", "grey", "black", "calico")
)

tidy_df
```

Messy data is inconsistent and unique, making it harder to work with, and harder for others to work with. See this example of a messy dataset that would be hard to work with. We would have to split up the animal column to name and colour. In later workshops, we will cover how to deal with messy data.

```{r}
# example messy data frame
messy_df <- data.frame(
  id = c(1,1,2,2,3,3,4,4,5,5,6,6),
  animal = c("floof", "grey",
             "max", "black",
             "cat", "orange",
             "donut", "grey",
             "merlin", "black",
             "panda", "calico")
)

messy_df
```

![Image credit: Julie Lowndes and Allison Horst](https://github.com/andrewmoles2/rTrainIntroduction/blob/main/r-data-wrangling-1/images/tidydata_2.jpeg?raw=true)

See this excellent article, which has lots of nice images, for a summary :-<https://www.openscapes.org/blog/2020/10/12/tidy-data/>


# Package install task

In this workshop we will be using three packages: magrittr, dplyr, and readr.

Using the code chunk below, install all three of these packages. Note that dplyr is large and might take a minute or so to install, we have added the `Ncpus = 6` argument which should speed things up a bit. 

```{r eval=FALSE}
# your code here
install.packages("", Ncpus = 6)
install.packages("", Ncpus = 6)
install.packages("", Ncpus = 6)
```

*Also note that you can install the whole tidyverse with install.packages("tidyverse")! This takes a while though, so for this workshop we will just install individual packages.*

# Intro to pipes

The pipe operator in R comes from the `magrittr` package, using syntax of `%>%`.

The pipe operator is for chaining a sequence of operations together. This has two main advantages: it makes your code more readable, and it saves some typing.

The syntax is `data %>% function`, as shown in the example below. The data gets *piped* into the function.

```{r}
library(magrittr)

data <- c(4.1 ,1.7, 1.1, 7.5, 1.7)

data %>% mean()
```

To see the difference between using pipes and not using pipes, look at the following examples.

We are going to calculate a mean of a vector of numbers, round the result, and print it using paste.

```{r}
# Make some data: 20 randomly selected data points, from 1 to 10
x <- sample(1:10, 20, replace = TRUE)
y <- sample(1:10, 20, replace = TRUE)

# without pipe
y_mean <- mean(y)
y_mean <- round(y_mean, digits = 2)
y_mean <- paste("Mean value of y is", y_mean)
y_mean

# without pipe in one line
paste("Mean value of y is", round(mean(y), digits = 2))
```

Now lets have a look at how to do this same set of operations with pipes. The process is as follows: assign x to x_mean, then pipe to x to a mean function, pipe the result of mean to round, finally assign result to paste.

You will notice in the paste function we have used a `.` after the text. This is called a *place-holder*, whereby instead of using the data (like we did above without the pipe) we add a `.` to tell R that is where we want our data to go.

```{r}
# load in magrittr
library(magrittr)

# magrittr pipe
x_mean <- x %>% # assign result at the start
  mean() %>% 
  round(digits = 2) %>%
  paste("Mean value of x is", .) # we use the . as a place holder for a variable (e.g. instead of x)

x_mean
```

Notice how we assign the result at the start just like we would usually do, then pipe from then on.

It is also worth mentioning that as of version 4.1 of R, base R comes with a native pipe operator. This has just been introduced, and may get more use in examples you'll see online in the future. The syntax uses `|>` as the pipe, and the structure is the same as a magrittr pipe.

*note that the native pipe currently doesn't have a place-holder, so we won't use paste in this example*

```{r}
# native R pipe
z <- sample(1:10, 20, replace = TRUE)

z_mean <- z |> 
  mean() |>
  round(digits = 2)

z_mean
```

If the above example doesn't work, it means you have a version of R that is less than 4.1. Run the below code chunk to test out your R version. If it is less than 4.1 you can update it after the workshop.

```{r}
# test your r version
R.version.string
```

We will be using the magrittr pipe (`%>%`) for the rest of this workshop, as it's currently the pipe operator you will come across most in the r world.

## Exercise - using pipes

Using the vector of temperature provided and using magrittr pipes:

1)  Pipe median and paste functions together to get a final result that looks like: *"median temp is 15"*
2)  Pipe max and paste functions together to get a final result that looks like: *"max temp is 20"*

*hint: don't forget to use the place-holder with paste*

```{r}
library(magrittr)

temperature <- c(10, 16, 12, 15, 14, 15, 20)

# your code here
mean_t = temperature %>%
  median() %>%
  paste("Median temp is", .)

mean_t

max_t = temperature %>%
  max() %>%
  paste("Max temp is", .)

max_t
```

# Introduction to dplyr

Dplyr is a package that is built for data manipulation, using functions that describe what they do. For example, the `select()` function selects columns you want, or don't want, from a data frame.

The dplyr package has a lot of functions built into the package, each has it's own very helpful documentation page with examples - <https://dplyr.tidyverse.org/reference/index.html>

![](https://github.com/andrewmoles2/rTrainIntroduction/blob/main/r-data-wrangling-1/images/dplyr_wrangling.png?raw=true){width="516"}

Dplyr functions work with and without pipes and you'll see both when searching online. If using a pipe, you call your data then pipe that to a function, such as `data %>% mean()`. If you are not using a pipe, you call your data within the function, such as `mean(data)`.

We will focus on two key dplyr functions for now: `select()` and `filter()`. We will use the messi_career data for the examples. Run the code chunk below to get the data into r and have a look at it.

```{r}
# create the messi career data
messi_career <- data.frame(Appearances = c(9,25,36,40,51,53,55,60,50,46,57,49,52,54,50,44),
                           Goals = c(1,8,17,16,38,47,53,73,60,41,58,41,54,45,51,31),
                           Season = c(2004,2005,2006,2007,2008,2009,2010,2011,2012,
            2013,2014,2015,2016,2017,2018,2019),
                           Club = rep("FC Barcelona", 16),
                          Age = seq(17, 32),
                          champLeagueGoal = c(0,1,1,6,9,8,12,14,8,8,10,6,11,6,12,3))
# view the data
head(messi_career)
```

## Select function

The select function subsets columns from a data frame using their name. There are several different ways of using select. Run each of the code chunks below and review the outputs.

First, we can give the names of the columns we want to select.

```{r message=FALSE, warning=FALSE}
# load dplyr
library(dplyr)

# select single column
messi_career %>% select(Goals)

# select all but single column
messi_career %>% select(-Goals)

# select multiple columns
messi_career %>% select(Appearances, Goals, Age)
```

Another method is using a range of columns, known as a slice. Here we are selecting columns from Season to Age, which includes the Club column as well. We can also combine this with the ! (not) operator to exclude those columns.

```{r}
# select slice (or range) of columns
messi_career %>% select(Season:Age)

# select slice and other columns
messi_career %>% select(Appearances:Season, champLeagueGoal)

# negate selection of columns
messi_career %>% select(!(Season:Age))

# negate selection with slice and extra column (note c() function used)
messi_career %>% select(!c(Season:Age, champLeagueGoal))
```

As you can see, `select()` makes it easy to extract columns from your data, and becomes more useful the larger your dataset becomes.

In the examples above we did not assign the result. See the examples below on how to do this.

```{r}
# assign result to subset
messi_sub <- messi_career %>%
  select(Appearances, Goals, Age)

messi_sub

# The no pipe method
messi_sub <- select(messi_career, Appearances, Goals, Age)
```

## Select exercise

For your exercises, you will be using imdb movie data! I've loaded it here in the code for you.

The data has 22 columns, some of which we won't need. We can use `select` to subset our data to keep only what we want.

1)  Run the code currenty in the code chunk to load the libraries and the data, and review the output from `glimpse()`
2)  Using select with pipes, subset the `imdb_movie` data so you have the following columns: imdb_id through to writer, actors, avg_vote to votes, reviews_from_users to reviews_from_critics. Assign the result to `imdb_sub`
3)  Use glimpse to review the subsetted data: *data %\>% glimpse()*
4)  There is a more efficient way of doing this using select. From looking at the examples provided, can you think of a better way of taking out the columns we removed?

*hint: you should be able to fit this into one select call*

```{r message=FALSE, warning=FALSE}
# load libraries
library(readr)
library(dplyr)

# load data
movies_imdb <- read_csv("https://raw.githubusercontent.com/andrewmoles2/rTrainIntroduction/main/r-data-wrangling-1/data/IMDb%20movies.csv")

# use glimpse to review data (tidyverse version of str())
movies_imdb %>% 
  glimpse()
  

# your code here
imdb_sub = movies_imdb %>%
  select(imdb_title_id:writer, actors, avg_vote:votes, reviews_from_users:reviews_from_critics) %>%
  glimpse()
```

# Select helper functions

So far we have selected just columns we named, but there are other methods we can use. Dplyr has a number of *helper* functions that come with `select()`.

One such example is the `contains()` function, that finds columns that contain the string a string. This is a useful option if you just want to pick out columns that have some similar text in them.

```{r}
# select by literal string
messi_career %>% select(contains("Goal"))
```

Other options are the `starts_with()` or `ends_with()` helpers. You provide a string of what your column either starts with or ends with, and they will be selected.

```{r}
# columns starting with A
messi_career %>%
  select(starts_with("A"))

# columns ending with s
messi_career %>%
  select(ends_with("s"))

# columns not starting with A
messi_career %>%
  select(!starts_with("A"))
```

## Select helper exercise

Using the imdb_sub dataset you made in the previous exercise:

1)  Find columns in imdb_sub that contain "vote"
2)  Find columns in imdb_sub that start with "d"
3)  Find columns in imdb_sub that end with "e"
4)  Find columns in imdb_sub that either start with "d" or end with "e" *hint: you can use an or (`|`) statement with select*

```{r}
# your code here
head(select(imdb_sub, contains("vote")))
head(select(imdb_sub, starts_with("d")))
head(select(imdb_sub, ends_with("e")))
head(select(imdb_sub, starts_with("d") | ends_with("e")))
```

# Using select to change column order

It is also helpful to change the order of your columns, and you can use `select` to do this.

If we wanted to move the club column as the first column in our messi_career data, we could do it manually but naming all the columns like the example below.

```{r}
# manually
messi_career %>%
  select(Club, Appearances, Goals, Season, Age, champLeagueGoal)
```

This could get really messy if you have lots of data. Two helper functions make this much easier: `everything()` and `last_col()`. Everything selects every column not already specified, so is useful if we want to move a column to the first column in the dataset.

```{r}
# move club to first column
messi_career %>%
  select(Club, everything())
```

Last col calls the last column in your data frame, so we can call `last_col()` to move 'champLeagueGoal' to the first column, then use everything to keep the rest of the columns as they are.

```{r}
# move last column to first column
messi_career %>%
  select(last_col(), everything())
```

Another option is to use the `relocate()` function. This has the same syntax as select, but has extra functionally for moving columns with the `.after` and `.before` arguments.

By default, relocate will move the column you specify to the first column.

```{r}
# default moves to first column
messi_career %>%
  relocate(Club)
```

We call `.after` and `.before` like the examples below. We can also move more than one column.

```{r}
# move club to col after champLeagueGoal
messi_career %>%
  relocate(Club, .after = champLeagueGoal)

# move club to col before champLeagueGoal
messi_career %>%
  relocate(Club, Goals, .before = champLeagueGoal)

```

## Column ordering exercise

Using the examples above:

1)  Move the `year` column to be the first column in the `imdb_sub` data frame
2)  Move the `avg_vote` column to be after the `year` column

```{r}
# your code here
imdb_sub %>%
  relocate(year) %>%
  relocate(avg_vote, .after = year)
```

# Filter function

The filter function allows you to subset rows based on conditions, using conditional operators (==, \<=, != etc.). It is similar to the base r `subset()` function which we have used in previous R workshops. The table below is a reminder of the conditional operators you can use.

| Operator   | Meaning                  |
|------------|--------------------------|
| `>`        | Greater than             |
| `>=`       | Greater than or equal to |
| `<`        | Less than                |
| `<=`       | Less than or equal to    |
| `==`       | Equal to                 |
| `!=`       | Not equal to             |
| `!X`       | NOT X                    |
| `X`        | Y                        |
| `X & Y`    | X AND Y                  |
| `X %in% Y` | is X in Y                |

Just like when using `select`, you provide the column name you want to apply conditional logic to. If you are piping, you don't need to provide your data as an argument in the function.

![](https://github.com/andrewmoles2/rTrainIntroduction/blob/main/r-data-wrangling-1/images/dplyr_filter.jpeg?raw=true){width="516"}

Run the examples below and review the outputs.

```{r}
# filter based on one criteria
messi_career %>% filter(Goals > 50)

# filter then pipe to select
messi_career %>% filter(Appearances >= 55) %>%
  select(Season, Age)

# filter on more than one condition
messi_career %>% filter(Goals > 50 & champLeagueGoal <= 10)

# filter on average
messi_career %>% filter(Goals > mean(Goals, na.rm = TRUE))
```

To assign the result to a new data frame (subset) we use the assignment operator at the beginning or the end of our code; here we have just shown the beginning, in the pipes section we show both versions.

```{r}
# assign result to messi_sub
messi_sub <- messi_career %>%
  filter(Appearances <= 40) %>%
  select(Goals, Age)

# view result
messi_sub
```

## Filter exercise

We are going to filter our subsetted (`imdb_sub`) data to find the best rated films from the USA in the year 1989, and create a subset called USA_1989_high.

1)  Pipe from imdb_sub to filter, filtering for country being equal to USA
2)  Pipe from your country filter to another filter, filtering for year being equal to 1989
3)  Pipe from your year filter to another filter. Filter for avg_vote to be greater than or equal to 7.5 and reviews_from_critics to be greater than 10
4)  Make sure to assign your result to USA_1989_high
5)  Print the result to see the highest rated films, made in the USA, in 1989.
6)  Do you think you can put this into one filter command using the & operator?

```{r}
# your code here
USA_1989_high = imdb_sub %>%
  filter(country == "USA") %>%
  filter(year == 1989) %>%
  filter(avg_vote >= 7.5 & reviews_from_critics > 10)

USA_1989_high
```

You might have noticed that the country column has some strings that are split by a comma, e.g. "Germany, Denmark". The == operator will not be able to pick these up. Instead we would use the base R `grepl()` function or `str_detect()` from the `stringr` package. This won't be covered in this workshop, but will be in future workshops. If you are interested, have a look at the stringr package - <https://stringr.tidyverse.org/index.html>.

# Other filtering options with dplyr

Other than conditional subsetting of data using `filter()`, dplyr has other functions we can use to subset our data: `slice`, `sample`, and `distinct.`

The sample functions randomly extract a set number of rows from your data. This is helpful if you want to take a random sample of your dataset. The examples below show the `sample_n()` and `sample_frac()` functions. 

```{r}
# sample 5 rows
messi_career %>%
  sample_n(5)

# sample 25% of your data
messi_career %>%
  sample_frac(0.25)
```

The slice functions are more useful. The basic `slice` function is the equivalent of using numbered indexing in base r `data[1:5, ]`, but is designed to work better in the tidyverse enviroment. 
```{r}
# select rows 4, 5, and 6
messi_career %>%
  slice(4:6)

# equivalent in base r
messi_career[4:6, ]
```

The `slice_max` and `slice_min` functions are much more powerful, and are harder and messier to achieve with normal base r code. They allow you to index the rows that have the max (or min) in a specified column. In the example, we extract the rows that have the top three and bottom three values in the Goals column. 
```{r}
# extract rows with top three Goals
messi_career %>%
  slice_max(Goals, n = 3)

# this harder and less clear in base r
messi_career[messi_career$Goals %in% tail(sort(messi_career$Goals), 3), ]

# extract rows with bottom three Goals
messi_career %>%
  slice_min(Goals, n = 3)
```

## Filtering continued exercise

In this exercise you will need to debug my code to get it working. We will filter the imdb_sub data for films over 120 minutes, and in the USA, then extract the top 20 rated films.  

If you get it working your `top_votes_USA` data frame should have 20 rows and 4 columns (title, year, genre and avg_vote) with films such as *The Shawshank Redemption* and *the Godfather*. As a bonus, if you get your code working, the plot at the end of the code will run! 

```{r eval=FALSE}
# your code here
top_votes_USA <- imdb_sub %>%
  filter(duration >= 120 & country == "USA") %>%
  slice_max(avg_vote, n = 20) %>%
  select(title, year, genre, avg_vote)

top_votes_USA

# fun extra, plot the output of your debugging! 
plot(top_votes_USA$year, top_votes_USA$avg_vote,
     col = "orange", # point colour
     pch = 16, # point type
     cex = 1.5, # point size
     xlab = "Year",
     ylab = "Average vote") 

```

# Individual coding challenge

For this coding challenge we are going to extract all Tolkien (lord of the rings and hobbit) and Harry Potter films from our imdb dataset. We have provided vectors with the titles of these films.

1)  Using the Tolkien and Potter vectors, use the `%in%` operator to filter titles in the imdb dataset that match the Tolkien or Potter vectors.
2)  Select out the title, year, avg_vote, and duration columns
3)  Save your subsetted data to a data frame called Tolkien_Potter
4)  What films in the Tolkien_Potter dataset have a higher than average vote?
5)  What films in the Tolkien_Potter dataset have a less than average duration in hours?

*hint: for 4 and 5 you can use filter to compare the column to the mean of that column, e.g. filter(data, column \> mean(column))*

```{r}
Tolkien <- c("The Lord of the Rings: The Fellowship of the Ring", "The Lord of the Rings: The Return of the King",
           "The Lord of the Rings: The Two Towers", "The Hobbit: An Unexpected Journey",
           "The Hobbit: The Desolation of Smaug", "The Hobbit: The Battle of the Five Armies")

Potter <- c("Harry Potter and the Sorcerer's Stone", "Harry Potter and the Chamber of Secrets",
            "Harry Potter and the Prisoner of Azkaban", "Harry Potter and the Goblet of Fire",
            "Harry Potter and the Order of the Phoenix", "Harry Potter and the Half-Blood Prince",
            "Harry Potter and the Deathly Hallows: Part 1", "Harry Potter and the Deathly Hallows: Part 2")

# your code here

```

------------------------------------------------------------------------

# R Data Wrangling 2 - Objective of workshop

To manipulate and create new columns using the mutate function from dplyr, as well as cleaning column names.

# What this workshop will cover

In this workshop, the aim is to cover how to perform data wrangling tasks on columns using dplyr. We will be covering:

-  Data manipulation with mutate from dplyr
-  Renaming columns 
-  Cleaning up column names with janitor

------------------------------------------------------------------------

# The mutate function

The mutate function is from the dplyr library, and is for making, modifying, or deleting columns in your dataset. Similar to what we have done in previous sessions, mutate allows you to make a new column from a calculation you have made.

![](https://github.com/andrewmoles2/rTrainIntroduction/blob/main/r-data-wrangling-1/images/dplyr_mutate.png?raw=true){width="516"}

The main difference between using mutate and making new columns in base R, is that mutate is smarter. You can create a new column based on a new column you have just made within mutate, which you can't do in base R. Lets look at some examples with our messi data we used in the last session.

In our previous workshops, we calculated Messi's goals per game (goals/appearances). We can do this with mutate. Notice the syntax, we give the name we want to call our new column first, then =, then what we want to do (e.g. a calculation);  `mutate(new_column = x/y)`.

*note: when loading dplyr you also load the magrittr library for piping*
```{r message=FALSE, warning=FALSE}
# load dplyr
library(dplyr)

# create the messi career data
messi_career <- data.frame(Appearances = c(9,25,36,40,51,53,55,60,50,46,57,49,52,54,50,44),
                           Goals = c(1,8,17,16,38,47,53,73,60,41,58,41,54,45,51,31),
                           Season = c(2004,2005,2006,2007,2008,2009,2010,2011,2012,
            2013,2014,2015,2016,2017,2018,2019),
                           Club = rep("FC Barcelona", 16),
                          Age = seq(17, 32),
                          champLeagueGoal = c(0,1,1,6,9,8,12,14,8,8,10,6,11,6,12,3))
# view the data
head(messi_career)

# calculate the goal to appearance ratio
messi_career %>%
  mutate(goal_ratio = Goals/Appearances)
```

The new column, goal_ratio in this case, will automatically be added to the end of your data frame. This is the same behaviour you will see when using base R. This behaviour can be altered if you want, but we won't have time to cover it here. 

What makes `mutate()` powerful, is the ability to do multiple calculations in one statement, as well as using newly made columns. See the below example which will help to understand this. We will use goal_ratio to find out the difference between goal_ratio and the average goal ratio for each row (or season).

```{r}
# calculate goal ratio and diff from mean
messi_career <- messi_career %>%
  mutate(
    goal_ratio = round(Goals/Appearances, digits = 2),
    diff_avg_goal_ratio = goal_ratio - (mean(Goals) / mean(Appearances)))

# print result
messi_career
```

We can then pipe this result to `filter()`, which allows us to see which seasons Messi has a goal ratio above his average goal ratio.

```{r}
messi_career %>%
  mutate(
    goal_ratio = round(Goals/Appearances, digits = 2),
    diff_avg_goal_ratio = goal_ratio - (mean(Goals) / mean(Appearances))) %>%
  filter(diff_avg_goal_ratio > 0)
```

## Mutate exercise 1

We will be using the imdb movies dataset again for this workshop. Use the code below to load in the data.  

```{r message=FALSE, warning=FALSE}
# load libraries
library(readr)
library(dplyr)

# load data
movies_imdb <- read_csv("https://raw.githubusercontent.com/andrewmoles2/rTrainIntroduction/main/r-data-wrangling-1/data/IMDb%20movies.csv")

# use glimpse to review data (tidyverse version of str())
movies_imdb %>% glimpse()
```

Lets pretend we are interested in the difference between the number of user reviews and critic reviews for each film in our movies_imdb dataset. We can use mutate to explore this difference a bit further.

1)  Pipe your movies_imdb data to a `mutate()` function. Make a new column called `user_critic_ratio`, and divide `reviews_from_users` by `reviews_from_critics`. Wrap the result in a `round()` function, rounding by two digits
2)  Now pipe to a `filter()` function, filtering country to be USA and year to be 1989
2)  Now pipe to a `select()` function, selecting the title, avg_vote and user_critic_ratio columns
3)  Now pipe to a `slice_max` function, extracting rows that had the top 10 avg_rating

You should get a data frame returned that has films including: The Abyss, Dead Poets Society, Do the Right Thing, and Glory.

```{r}
# your code here


```

We can see we get more user reviews than critic reviews, which makes sense; for example, the The Abyss has 4 user reviews for each critic review.

## Mutate exercise 2

In our second mutate exercise, you will need to de-bug the code to get it running! You may need to re-order some elements of the code as well as checking for other errors. 

We are filtering the movies_imdb data for films that are from the USA before the year 1990, have a duration less than 120 minutes, and an average vote greater than 8.5. We will also be using the user_critic_ratio column to make it into a string for easier reading. 

You should end up with a data frame with 6 rows, and 4 columns (title, year, avg_vote, and ratio_string). The final column, ratio_string, should have an output like "Psycho has a user to critic ratio of 5.44". 

```{r eval=FALSE}
# your code here
usa_pre90_high <- movies_imdb |>
  mutate(user_critic_ratio = round(reviews_from_users / reviews_from_critics, digits = 2),
         ratio_string = paste(title, "has a user to critic ratio of", userCriticRatio)) %>%
  filter(country == "USA" & year < 1990) 
  select(title, year, avg_vote, ratio_string) %>%
  filter(duration < 120 & avg_vote >= 8.5)
  
usa_pre90_high
```


# Mutate with the across function

We can take the mutate function further by using the `across()` function. This allows us to perform operations (do something) across multiple columns. This is very useful for doing type conversions in an efficient way.

The across function works in a similar way to the `select()` function, but if you want to pick out a few columns you have to use the `c()` function. See the examples below, where we have selected two columns, or used a slice to select out a few columns that are next to each other.

```{r}
# perform round (to 1 decimal place) across selected columns
messi_career %>%
  mutate(across(c(goal_ratio, diff_avg_goal_ratio), round, digits = 1))

# square root across columns selected with slice
messi_career %>%
  mutate(across(1:3, sqrt))

# square root across columns selected with slice (using col names)
messi_career %>%
  mutate(across(Appearances:Season, sqrt))
```

We can also combine the across function with the `where()` or `all_of()` functions to perform conditional mutations.

The `where()` function does conditional matching between the statement you've used and what is in your dataset. In the example we are asking `where()` to look for columns that are the character (string) data type. Then we can perform an operation, such as convert those columns to factors. In this case it is just the Club column that changes. 

```{r}
# perform conditional operation with where
messi_career %>%
  mutate(across(where(is.character), as.factor)) %>%
  glimpse()
```

The `all_of()` function looks for matches between the strings you have provided and the column names in your dataset. In our example, we put the Season and Club columns into a vector, then call that vector and convert those columns to a factor.

```{r}
# change selected variables with all_of
to_factor <- c("Season", "Club")

messi_career %>%
  mutate(across(all_of(to_factor), as.factor)) %>%
  glimpse()
```

## Across function exercise

Lets go back to our movies_imdb data. We want to extract films from 1990 through to 1995, that are from the USA, and have an avg_vote greater than or equal to 7.5. We also want all our variables that are currently characters to be factors, and want the year column to also be a factor.

1)  Using the movies_imdb data, filter for years between and including 1990 and 1995
2)  Now also filter for the country to be the USA, with an avg_vote greater then or equal to 7.5
3)  Using mutate, across and where, convert any column that has a character data type to a factor
4)  Using mutate, convert year to a factor
5)  Save the result in a data frame called `usa_early90_high`
6)  Using your new `usa_early90_high` subset, filter for avg_vote greater than or equal to 8.5, then select the title, avg_vote, and year columns. View the result to see the top rated films and what year they were in.

```{r}
# your code here
usa_early90_high = movies_imdb %>%
  filter(year >= 1990 & year <= 1995, country == "USA", avg_vote >= 7.5) %>%
  mutate(across(where(is.character), as.factor)) %>%
  mutate(year = as.factor(year))
  
usa_early90_high %>%
  filter(avg_vote >=  8.5) %>%
  select(title, avg_vote, year)
```

# Ranking and cumulativate calculations using mutate

It can sometimes be helpful to rank your dataset, using mutate and the `min_rank()` or `percent_rank` functions allow you to add a new column with a rank based on a important column. Higher rank or percent rank means a better ranking. 

In this example, we want to make a goal ranking column and a percent raking column. We can then use filter to select rankings we are interested in. 
```{r}
messi_career <- messi_career %>%
  mutate(goal_rank = min_rank(Goals),
         goal_perc_rank = percent_rank(Goals))

# select rankings over 10
messi_career %>%
  filter(goal_rank > 10)
```

Another useful calculation you can do is to do cumulativate calculations, such as cumulativate sum or mean of a useful variable. For example, in our messi_career data it might be interesting to workout  his cumulativate goals, and average cumulativate appearances. We use the `cumsum()` and `cummean()` functions for these calculations. 

*note: cumulativate calculations are work very well with longitudinal data, like we have for Lionel Messi's career goals and appearances*

```{r}
messi_career %>%
  mutate(cumul_goals = cumsum(Goals),
         mean_cumul_app = cummean(Appearances)) %>%
  select(Goals, cumul_goals, Appearances, mean_cumul_app)
```

## Ranking and cumulativate calculations exercise

Using your usa_early90_high data we just made in the last exercise:

1)  Use mutate to make a new column called `duration_rank`, using the `min_rank()` function on the duration column
2)  In the same mutate statement, make a new column called `perc_duration_rank`, using the `percent_rank()` function on the duration column
3)  In the same mutate statement, make a new column called `avg_cumul_duration`, using the `cummean()` function on duration. 
4)  Pipe to a filter function, and filter for perc_duration_rank between 0.5 and 0.6
5)  Use select to extract the following columns: title, year, duration, avg_vote, duration_rank, perc_duration_rank, and avg_cumul_duration. 

```{r}
# your code here
usa_early90_high %>%
    mutate(
      duration_rank = min_rank(duration),
      perc_duration_rank = percent_rank(duration),
      avg_cumul_duration = cummean(duration)
    ) %>%
    filter(perc_duration_rank <= 0.6 & perc_duration_rank >= 0.5) %>%
    select(title, year, duration, avg_vote, duration_rank, perc_duration_rank, avg_cumul_duration)
```

# The transmute function

The `transmute()` function in dplyr works in a similar way to `mutate()`, but it drops all columns *except* those it has just made. 

```{r}
# use transmutate
messi_career %>%
  transmute(cumul_goals = cumsum(Goals),
         mean_cumul_app = cummean(Appearances))
```

The behaviour of transmute can be helpful in certain situations, but if you really want to keep some columns, you can add them into the transmute statement. For example, in the example below I might want to keep the Goals and Appearances columns for comparison with the cumulativate calculations I've made. 

```{r}
# keep Goals and Appearances
messi_career %>%
  transmute(cumul_goals = cumsum(Goals),
         mean_cumul_app = cummean(Appearances),
         Goals, 
         Appearances)
```
## Transmute exercise

Let's use transmute to look at the durations of the films in the imdb_movies data. 

1)  Pipe movies_imdb to `transmute()`
2)  Make a variable called duration_hours, which converts duration to hours *hint: look online for minute to hour conversion*
3)  In the same `transmute()` make a variable called duration_rank, and use the `min_rank()` function on duration
4)  Include the year, title, duration, and genre columns. 
5)  Assign the result to movie_durations
6)  Using `filter()`, `slice_max()` or `slice_min()`, find out the top 4 and bottom 4 film durations

```{r}
# your code here


```


# Change column names

Changing column names is a very useful part of data science. Sometimes you'll get a dataset with column names that are not very meaningful, or far too long. There are a few methods for changing column names, with the easiest being the tidyverse solution. 

The first step in changing column names is viewing what the names are! Two functions in R exist for this: `colnames()` and `names()`. They do the same thing...so I prefer `names()` as it is less typing. 
```{r}
# view a datasets column names
names(messi_career)
```

The non-tidyverse way of changing column names is to use the `names()` function. If you are changing one column you use indexing using `[]`, and multiple columns you use `c(). 
```{r}
# Make a data frame
df <- data.frame(
  column1 = rep("Hello", 4),
  column2 = sample(1:10, 4),
  column3 = seq(1:4),
  integer = 4:7,
  factor = factor(c("dog", "cat", "cat", "dog"))
)

df

# change multiple columns using names
names(df) <- c("string", "random", "sequence", "integer", "factor")
names(df)

# using names and number index
names(df)[1] <- "a_string"
names(df)

# using logic and names
names(df)[names(df) == "sequence"] <- "its_a_sequence"
names(df)
```

The main issue with these techniques is 1) it can get really messy if you need to rename lots of columns in a larger dataset. 2) I have to rename all my columns if I need to rename more than one column, otherwise it doesn't work! 3) The syntax is a bit messy, especially the last example. 

The `rename()` function from dplyr allows for simple changing of column names with no fuss, and solves these problems. 

The syntax is the same as the `mutate()` function, where we have the name of the column we want to make, then what column we are changing: `data %>% rename(new_column_name = old_column_name)`. 

```{r message=FALSE}
# load dplyr
library(dplyr)

# Make a data frame
df <- data.frame(
  column1 = rep("Hello", 4),
  column2 = sample(1:10, 4),
  column3 = seq(1:4),
  integer = 4:7,
  factor = factor(c("dog", "cat", "cat", "dog"))
)

names(df)

# rename columns that need renaming
df_new_col <- df %>%
  rename(string = column1,
         random = column2,
         sequence = column3) 

df_new_col
```

## Rename columns exercise

Let's have a practice renaming some columns in the movies_imdb dataset. 

1) Type in and run `names(movies_imdb)` to get the column names of your dataset. This is a nice way to finding the column names, making it easy to copy and paste the names should you need to
2) Using the `rename()` function from dplyr, change `reviews_from_users` to `User_reviews` and `reviews_from_critics` to `Critic_reviews`
3) Save the result back to `movies_imdb`
4) Type in and run `names(movies_imdb)` again to view the new column names

```{r}
# your code here

```


# Tidy column names with janitor

Sometimes you have a dataset that has messy or ugly column names, which would take some time to tidy up manually. As usual with R there is a package for that situation; which happens more often than you think! 

First, we need to install the `janitor` library. 

```{r eval=FALSE}
# run to install janitor
install.packages("janitor")
```

A simple example is below. We have a data frame with inconsistent column names. We use the `clean_names()` function from janitor to tidy up the column names. 

The output shows the difference between default R behaviour and how janitor has cleaned the names. As you can see the janitor output is consistent and in "snake_case" format. 
```{r}
# load janitor
library(janitor)

# make an example data frame
messy_cols <- data.frame(
  'messyCol *1' = seq(1:5),
  'messy.col 2' = seq(1:5),
  'MESSY.COL 3' = seq(1:5),
  'messy.col (4)' = seq(1:5)
)

# compare default to janitor col names
data_frame(default = names(messy_cols),
           janitor = names(clean_names(messy_cols)))

```

The janitor library is designed to be used with the tidyverse, so when loading in data, we can pipe our loaded data straight into the `clean_names()` function form janitor.

```{r}
# pipe data to clean names
messy_cols <- data.frame(
  'messyCol *1' = seq(1:5),
  'messy.col 2' = seq(1:5),
  'MESSY.COL 3' = seq(1:5),
  'messy.col (4)' = seq(1:5)
) %>% clean_names()

# view col names
names(messy_cols)
```

You can change the default style, or case, of `clean_names()` from snake case to another if you need or want to. See some examples below.
```{r}
# lower camel case
data.frame(
  'messyCol *1' = seq(1:5),
  'messy.col 2' = seq(1:5),
  'MESSY.COL 3' = seq(1:5),
  'messy.col (4)' = seq(1:5)
) %>% clean_names(case = "lower_camel")

# title case
# This is useful for plotting or tables
data.frame(
  'messyCol *1' = seq(1:5),
  'messy.col 2' = seq(1:5),
  'MESSY.COL 3' = seq(1:5),
  'messy.col (4)' = seq(1:5)
) %>% clean_names(case = "title") 

# all_caps case
data.frame(
  'messyCol *1' = seq(1:5),
  'messy.col 2' = seq(1:5),
  'MESSY.COL 3' = seq(1:5),
  'messy.col (4)' = seq(1:5)
) %>% clean_names(case = "all_caps") 
```

A full list of what different cases are available are on this page under the case arguments: <https://rdrr.io/cran/snakecase/man/to_any_case.html>

Finally, you can decide if you want the numbers (if you have any) to be aligned in the left, right, or middle of the column name. By default `clean_names()` puts numbers to the middle/right. To change this behaviour we use the numerals argument and specify left as shown below. 

```{r}
data.frame(
  'messyCol *1' = seq(1:5),
  'messy.col 2' = seq(1:5),
  'MESSY.COL 3' = seq(1:5),
  'messy.col (4)' = seq(1:5)
) %>%
  clean_names(numerals = "left") 
```

## Clean names exercise
As the movies_imdb data we are using already has cleaned names, we will load in another dataset as an example: the pokemon dataset we have used in previous workshops. 

1)  Load in the `janitor` and `readr` librarys
2)  Use `read_csv()` to load in the pokemon dataset from this link <"https://raw.githubusercontent.com/andrewmoles2/rTrainIntroduction/main/r-fundamentals-5/data/pokemonGen1.csv">. Call your data pokemon
3)  Use `read_csv()` to load in the same pokemon dataset from the link, but this time pipe to `clean_names()`. Call this dataset pokemon_cleaned
4)  Follow the steps in step 3 again, but this time in your `clean_names()` function, change the case used. Call this dataset pokemon_cleaned2
5)  Now make a data frame to compare your column names from your three loaded datasets. To do this, call a `data.frame()` function. Make your first column `default = names(pokemon)`, second column `cleaned = names(pokemon_cleaned)`, and your last column `cleaned2 = names(pokemon_cleaned_2)`. Run the code to review the output

*Different cases available can be found at this link: <https://rdrr.io/cran/snakecase/man/to_any_case.html>*
```{r message=FALSE}
# your code here

```

# Final task - Please give us your individual feedback!

We would be grateful if you could take a minute before the end of the workshop so we can get your feedback!

<https://lse.eu.qualtrics.com/jfe/form/SV_eflc2yj4pcryc62?coursename=Fast-track:RDW12&topic=R&link=https://lsecloud.sharepoint.com/:f:/s/TEAM_APD-DSL-Digital-Skills-Trainers/EkNl1TlFgF9ApLsKSP-lqTUBiMCNlzcqB8pY0W3IJI3WYQ?e=cWodPf&prog=DS&version=21-22&link2=https://lsecloud.sharepoint.com/:f:/s/TEAM_APD-DSL-Digital-Skills-Trainers/ErMphV2T01BNmDCWbkZRu_MBCqLgU46EcfVef7r4yZJ_dQ?e=E2fPrL>

The solutions we be available from a link at the end of the survey.

# Individual coding challenge

In this coding challenge we will try and put together what we have learned in this and previous workshops. 

We will be using data from the pokemon games, making some subsets from that data. If you are curious about the data, have a look at the source here: <https://pokemondb.net/pokedex/all>. 

1)  Make sure you have the following packages loaded: dplyr, readr, janitor
2)  Load in the pokemon data using the following link: "https://raw.githubusercontent.com/andrewmoles2/webScraping/main/R/data/pokemon.csv". Call your data `pokemon`
3)  Clean up the column names using janitor. Try and use pipes like we did in the examples earlier in the workshop
4)  Using mutate, change all data that is a character in `pokemon` to a factor
5)  In the same mutate, add columns for speed_rank and hp_rank. Use the `min_rank()` function on speed and hp to calculate the rankings
6)  Pipe to a filter function. Keep only data that has been defined as not legendary (*legendary = FALSE*) and is less than or equal to generation 4. You should end up with the legendary column all being false and generation being 1-4
7)  Pipe to another filter function, subsetting total to be greater than or equal to 500
8)  Assign the result of this subset to `pokemon_500`
9)  Make four different subsets called: slow, fast, high_hp, and low_hp. Pipe your `pokemon_500` data to slice_max or slice_min functions to find the top 10 fastest/slowest pokemon, and the top 10 highest/lowest hp pokemon. For example, `slow <- pokemon_500 %>% slice_min(speed_rank, n = 10)`
10) Find out which pokemon feature in both the high_hp data and the slow data *hint: use filter and the `%in%` operator*
11) Find out which pokemon feature in both the fast data and the low_hp data
12) Bonus: run the code for the barplot (second code chunk). It uses the `pokemon_500` data you made to see which pokemon types have total statistics over 500. The colours represent each pokemon type (grass is green etc.). It won't run if `pokemon_500` has not been made or named differently. 

```{r message=FALSE}
# your code here

```

Bonus code (see part 12 of coding challenge)
```{r eval=FALSE}
# bonus - see a bar plot of your pokemon types
# make a colour palette of the pokemon types
colour <- c("#6a8b5a", "#414152", "#5a8bee", 
            "#f6e652","#ffd5bd", "#b40000", 
            "#ee8329","#6ab4e6", "#8b6283", "#20b49c", 
            "#c57341", "#e6e6f6", "#ffffff", 
            "#a483c5", "#f65273", "#e6d5ac", 
            "#bdcdc5", "#083962")

# view the colours
#scales::show_col(colour)

# plot in a bar plot
barplot(height = table(pokemon_500$type1),
        col = colour,
        horiz= TRUE, las= 1, 
        xlim = c(0, 20),
        xlab = "Frequency", 
        main = "Freqency of Pokemon types\n with total greater than 500")
```

If you are wondering how the colouring works, we are using the factor levels of the type1 column. If you type `levels(pokemon_500$type1)` you'll get a vector with the 18 different factor levels, with Bug being 1 and Dark being 2 and so on. The first element in our colour vector therefore matches up with the first level of the type1 factor, which is bug.

